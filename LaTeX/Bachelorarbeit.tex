\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}
\usepackage{url}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{setspace} % Paket für Zeilenabstand

\pagestyle{fancy}
\fancyhf{}
\chead{\thepage} % Seitenzahl zentriert oben
\renewcommand{\headrulewidth}{0pt} % Keine Kopfzeilenlinie

\newcommand{\bracenom}{\genfrac{\lbrace}{\rbrace}{0pt}{}}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{RGB}{4,118,219}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{RGB}{0,27,51}
\definecolor{textcolour}{RGB}{38, 149, 245}



\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\color{textcolour}\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=false,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}



\usepackage{setspace}
\onehalfspacing
%\doublespacing

\lstset{literate=%
    {Ö}{{\"O}}1
    {Ä}{{\"A}}1
    {Ü}{{\"U}}1
    {ß}{{\ss}}1
    {ü}{{\"u}}1
    {ä}{{\"a}}1
    {ö}{{\"o}}1
    {~}{{\textasciitilde}}1
}

\lstset{style=mystyle}

    \title{\textbf{Bachelorarbeit}}
    \author{Jan Philipp Fortowski}
    \date{xx.xx.2024}
    
    \addtolength{\topmargin}{-3cm}
    \addtolength{\textheight}{3cm}
\usepackage{graphicx}

\usepackage[left=4.5cm, right=1.5cm, top=3cm, bottom=2.5cm]{geometry}
\setstretch{1.5} % Zeilenabstand von 1,5
\setcounter{page}{-1}
\begin{document}


\maketitle
\thispagestyle{empty}
\cleardoublepage
% \phantomsection
\tableofcontents
\thispagestyle{empty}
\cleardoublepage
% \phantomsection



\section{Fully Connected Layer / Feed Forward Layer}
In diesem Kapitel werden die Fully Connected Layer betrachtet, welche genau so aufgebaut sind, wie bei den Feed Forward Networks. genau genommen wird im Prinzip einfach ein Feed Forward network am Ende des Convolutional networks eingesetzt, denn die Fully Connected layer werden nur am Ende benutzt. Wenn in einem netzwerk nur die Fully Connected Layer verwendet werden, dann handelt es sich um ein Feed Forward Network. 
Das Grundprinzip ist vergleichbar kompliziert. Jede Schicht enthält sogenannte Knoten. Diese Knoten sind mit den Neuronen in einem Gehirn vergleichbar.

\begin{figure}[H]
\centering
\includegraphics[scale=0.40]{./Images/BA_001_DasNeuron.png}
\caption{Das Neuron}
\label{Was kommt hier rein?}
\end{figure}

FeedForwardNetzwerk

Alle Knoten einer Schicht, sind mit allen Knoten der nächsten Schicht verbunden. Diese Verbindungen werden gewichtet, also müssen Gewichte gespeichert werden, die festlegen, wie wichtig der Input eines jeweiligen Knotens für den Aktuellen Knoten ist. Diese Knoten können angepasst werden, das heißt, dass kleine inkrementelle Anpassungen mit jeder Lern-Iteration vorgenommen werden, um das Netzwerk Stück für Stück einem Fehler-Minimum anzupassen. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.50]{./Images/BA_002_FeedForwardNetzwerk.jpg}
\caption{Das Neuronale Netzwerk}
\label{Das Neuronale Netzwerk}
\end{figure}

Besonders für Lineare Problemen, die nicht durch den Nullpunkt eines Koordinatensystems gehen ist es Notwendig, auch Biases mit einzurechnen. Für die Bild Erkennung ist das normalerweise nicht wichtig, und da sich die Convolutions auf die Bilderkennung Spezialisieren, wird es für dieses Projekt nicht notwendig sein, Biases einzuplanen.

In diesem Kapitel werden nun zunächst der generelle Aufbau der Klasse "FullyConnectedLayer" dargelegt, und in den beiden Unterkapiteln wird dann speziell auf den ForwardPass und auf die Backpropagation eingegangen, zusammen mit den Mathematischen Grundlagen und dem dazugehörigen Code.

Zunächst muss die Klasse erstellt werden. Die Objektvariablen sind diese:
    
\begin{lstlisting}[language=Java]
public class FullyConnectedLayer extends Layer {
    double[][] weights;
    int inLength;
    int outLength;
    double learnRate;

    private double[] lastZ;
    private double[] lastInput;
\end{lstlisting} 
in den "weights" werden die Gewichte gespeichert zwischen den Inputs und den Knoten der Schicht. Diese können angepasst werden, um den Fehler des Netzwerkes zu minimieren und damit korrekte Klassifizierungen vorgenommen werden können.
Mit "inLength" ist die Menge an Inputs gemeint, das heißt zum Beispiel wie viele Pixel die Bilder haben, die in die Schicht eingespeißt werden.
Der Parameter "outLength" entspricht dann auch der Menge an Outputs welche von der Schicht erzeugt werden. Das hängt davon ab, wie viele Knoten die nächste Schicht hat, oder wenn es die letzte Schicht ist, wie viele mögliche Antworten das Netzwerk hat.
Die "learnRate" schränkt die größe der Inkremente zwischen den einzelnen gelernten Bildern ein. Dies ist Notwendig, da die berechneten Inkremente, also die Steigung im Fehlergraphen, normalerweise zu groß sind, und die Fehler Minima dadurch häufig übersprungen werden. Das Netzwerk soll sich aber dem Fehlerminimum langsam annähern, also müssen die Schritte kleiner sein. Zu klein sollten sie aber auch nicht sein, weil das Netzwerk dadurch deutlich langsamer wird, und eine zu langsame Annäherung unter Umständen das Ziel nicht erreicht, bevor der Lernprozess abgeschlossen ist..

%DONE Bild von Lernrate zu groß und zu klein
\begin{figure}[H]
\centering
\includegraphics[scale=0.50]{./Images/BA_006_LearnRate.jpg}
\caption{Learn Rate}
\label{Learn Rate}
\end{figure}

Mit dem Array "lastZ" und "lastInput" sollen jeweils für die Backpropagation Notwendige Zwischenschritte gespeichert werden. "lastZ" entspricht den Inputs multipliziert mit den Gewichten. Das bedeutet hierbei handelt es sich um die Ergebnisse der Schicht bevor sie durch die Activation Funktion umgerechnet werden. Mit "lastInput" sind einfach die Inputs gemeint, die zuletzt in diese Schicht geleitet wurden, und noch keinen Rechnungen unterlegen sind. Genaueres wird im Unterkapitel zur Backpropagation betrachtet, aber diese Werte werden uns später noch von Nutzen sein.


\subsection{Forward Propagation in der Fully Connected Layer}

Für den Forward Pass, also die Grundfunktion in der Querry, muss ein Array erstellt werden, welches die outputs der Schicht enthält. Beim Fully Connected Layer entspricht die menge an Outputs der menge der Knoten aus der nächsten Schicht. Ein Wert in der Output menge wird berechnet, indem jeder Input in die Schicht mit dem Gewicht multipliziert wird, welches zwischen jedem Knoten in dieser Schicht und dem Knoten der nächsten Schicht gespeichert wurde. Alle diese Werte werden dann multipliziert, und mit einer Activation Funktion umgerechnet. Dies ist dann der Output, der an die nächste Schicht übergeben wird. Hier im Code wird dieser Output durch das Array "a" dargestellt, um auf das Ergebnis der Activation hinzuweisen.

Abgesehen davon werden allerdings auch noch die Werte lastInput und das Array "Z" zwischengespeichert. Diese Werte sind für die Backpropagation notwendig, daher werden die Details auch erst im nächsten Kapitel behandelt. Aber im Prinzip steht das Array "Z" für die Zwischenergebnisse, die noch mit der Activation Funktion verrechnet werden müssen.

"lastInput" ist an sich Selbs erklärend, hier wird einfach der letzte Input zwischengespeichert, also einfach die Werte, die bei der Querry aus der letzten Schicht eingereicht wurden, und noch nicht weiter verrechnet wurden.
\clearpage
\begin{lstlisting}[language=Java]
    public double[] FullyConnectedForwardPass(double[] input){
        lastInput = input;
        double[] Z = new double[outLength];
        double[] a = new double[outLength];
        //Diese schleife summiert alle Inputs auf alle outputs, und multipliziert die Inputs mit ihren jeweiligen gewichten aus der weights-Matrix
        for(int i=0; i<inLength; i++){
            for(int j=0; j<outLength;j++){
                Z[j] += input[i]*weights[i][j];
            }
        }
        
\end{lstlisting}
Nach dieser Schleife sind die Inputs mit den Gewichten verrechnet, aber die Activation Funktion wurde noch nicht angewendet. Also sollten diese Werte unter "lastZ" zwischengespeichert werden.
\begin{lstlisting}[language=Java] 
        lastZ = Z;
		//Diese Schleife wendet auf alle Outputs die Activation Funktion an, in diesem Falle die Sigmoid Funktion
        for(int i=0; i<inLength; i++){
            for(int j=0; j<outLength;j++){
                a[j] = Sigmoid(Z[j]);
            }
        }
        return a;
    }
\end{lstlisting} 

Das Array welches zurückgegeben wird, ist der komplette berechnete Output, und kann so an die nächste Schicht weitergeleitet werden. Im Convolutional Network kommen die Fully Connected Schichten immer ans Ende. Die Convolution Layer und die MaxPool Layer sind auf die Erkennung von Features in Bildern und auf die Komprimierung und Verdichtung relevanter Daten in den Bildern Spezialisiert. Daher macht es keinen Sinn, diese Schichten nach einem Fully Connected Layer einzusetzten. Das Bild kann aus den Ausgaben einer Fully Connected Layer nicht wieder rekonstruiert werden, und ist daher für die anderen Schichten nicht mehr nutzbar. Es kann also davon ausgegangen werden, dass nach einem Fully Connected Layer nur noch weitere Fully Connected Layer auftreten werden. 
Außerdem soll hier angemerkt werden, dass die Convolution und Pool Layer zwar die Bilderkennung Positiv beeinflussen, simple Netzwerke bereits rein und ausschließlich mit Fully Connected Layeren aufgebaut werden können. Diese sind zwar sehr anfällig auf leichte Veränderunegn der Inputs, und die Genauigkeit lässt daher ein wenig zu wünschen übrig, aber durchaus verlässliche Ergebnisse können damit schon erzielt werden.

Da die Outputs der Fully Connected Layer keine direkten Rückschlüsse auf die Bilder zulassen, die zu Anfang in das Netzwerk gegeben werden, wird bei den in der Abstrakten Klasse definierten Methoden zur Rückgabe der verschiedenen Parameter auch anders verfahren, als in den anderen Layer Klassen. Die anderen Layer Klassen müssen Auskunft darüber geben können, wie viele Output Bilder sie erzeugen, und welche Dimensionen diese besitzen. Zum Beispiel gibt die Max Pool Layer zwar komprimierte Bilder zurück, das heißt dass die Dimensionen kleiner geworden sind. Allerdings werden alle Bilder, die in die Schicht eintreten, mit jedem Filter Fenster verrechnet, welches die Schicht besitzt. Das heißt die menge der Output Bilder ist die Menge der Input Bilder mal die Menge der Filter. Diese Informationen sind für die nachfolgenden Schichten von großem Wert. Bei den Fully Connected layern können nur Fully Connected layer folgen, also ist auch nur die Menge der Inputs wichtig, da Fully Connected Layer die Inputs als ein einziges 1-Dimensionales Array betrachten. Also muss nur die "getOutputElements" Methode sinnvoll betrachtet werden, diese gibt einfach die "outLength" Variable zurück. Alle anderen get-Methoden können 0 zurück geben.

\begin{lstlisting}[language=Java] 
    public int getOutputElements() {
        return outLength;
    }
\end{lstlisting} 
\clearpage
\subsection{Backpropagation im Fully Connected Layer}
Backpropagation ist der Prozess, den Fehler, den ein Netzwerk macht zu Quantifizieren, und dann über alle Schichten zurückzuverfolgen. Dabei wird durch das Ableiten der Fehlerfunktion festgestellt, wie die Gewichte oder andere veränderbaren Attribute angepasst werden müssen, um sich dem Fehlerminimum zu nähern. Das Fehlerminimum wird durch kleine, inkrementelle Schritte angepeilt. Diese Schrittweise Annäherung nennt man Gradient Descent. 

Das Gradient Descent Verfahren funktioniert so, dass ein gegebenes Gewicht $w^0$ in die Fehlerfunktion $C_0$ eingesetzt wird, also die Funktion, die den Fehler quantifiziert, den das Netzwerk bei der Klassifizierung eines Bildes gemacht hat. Durch die Ableitung dieser Funktion an der gegebenen Stelle, kann eine Steigung berechnet werden, welche die Richtung angibt, in die das Gewicht angepasst werden sollte, um sich dem Fehlerminimum zu nähern. 
Das heißt also, wenn 

$C_0'(w^0)>0$, dann sollte das Gewicht $w^1$ ein Stück weiter links von $w^0$ sein, und wenn

$C_0'(w^0)<0$, dann sollte das Gewicht $w^1$ ein Stück weiter rechts von $w^0$ sein.

Das lässt sich auch algorithmisch notieren:

$$w^k:=w^{k-1}-\lambda C'(w^{k-1}), k \geq 1$$

wobei $\lambda > 0$ ist, denn $\lambda$ entspricht der Learnrate, also dem Skalierungsmaß für die Inkremente, in denen die Gewichte angepasst werden. Ohne das Skalierungsmaß wären die Anpassungen zu groß, und würden die Fehlertiefpunkte regelmäßig weit überspringen, anstatt sich ihnen anzunähern [1, S.114 ff.]. 

Zuerst sollte man die Fehlerfunktion betrachten. 
Es sei der letzte Output aus dem Netzwerk genannt $O_L$. Außerdem werden die Targets, also die angestrebten Werte, für das Bild benötigt. Um ein Neuronales Netzwerk zu trainieren, braucht man nicht nur die zu klassifizierenden Inputs, diese Inputs müssen auch mit Labeln versehen sein. Ein Label gibt an, was auf dem Bild zu sehen ist. Das Ziel ist es, dass das Netzwerk eine Ausgabe macht, die sich möglichst wenig von dem Label unterscheidet. Hier kommen die Targets ins Spiel. Im Prinzip erstellt man ein Array, welches für jede Antwortmöglichkeit des Netzwerkes ein Feld besitzt. Das Feld, das dem Label entspricht, wird auf 1 gesetzt, alle anderen Felder werden auf 0 gesetzt. Dies sind die Targets $T$.

Um nun die Loss oder auch Cost Funktion $C$, also die Fehlerfunktion zu berechnen, müsste man nur die Targets von den Outputs abziehen, allerdings sollten die Ergebnisse noch Quadriert werden. Das hat zwei Vorteile, der erste Vorteil ist, dass Fehler dadurch betont werden. Große Fehler haben dadurch einen noch größeren Einfluss. Das hilft, sich nicht zu schnell oder zu langsam dem Fehlerminimum anzupassen. Der zweite Vorteil ist der, dass durch das Quadrieren alle Fehler Positiv werden. Alle Fehler müssen nachher summiert werden. Wenn es Positive und negative Fehler gibt, würden sich diese gegenseitig aufheben. 
Alles in allem sieht die Fehlerfunktion für dieses Netzwerk dann so aus:

$$C_0 = (O_L - T)^2$$

Nun gilt es, herauszufinden, wie sich die Fehlerfunktion ändert, im Bezug auf die Gewichte und anderen veränderbaren Parameter im Netzwerk.

Dazu kann man Notieren dass die Ableitung von $C_0$ gesucht ist, im Bezug auf eine Änderung an $w_L$, damit gemeint sind die Gewichte aus der letzten Schicht.

$$\frac{\delta C_0}{\delta w_L}$$

Diese Ableitung lässt sich dank der Kettenregel weiter aufschlüsseln, sodass einzelne Komponenten entstehen, die mit Code berechnet werden können.

$$\frac{\delta C_0}{\delta w_L}=
\frac{\delta Z_L}{\delta w_L}*
\frac{\delta a_L}{\delta Z_L}*
\frac{\delta C_0}{\delta a_L}$$

Diese Terme können einzeln entschlüsselt und im Code verwendet werden. Der erste Term ist

$$\frac{\delta Z_L}{\delta w_L}$$

und beschreibt die Ableitung der Berechnung in den Knoten bevor die Transferfunktion, also zum Beispiel die Sigmoid Funktion eingesetzt wird, im Bezug zu den Gewichten der letzten Schicht.
Diese Berechnung sieht erst einmal so aus:

Jede Schicht besitzt eine Menge an Knoten, die den Neuronen des Gehirns nachempfunden sind. Ein Knoten ist mit allen Inputs verknüpft, also mit dem Bild das in die erste Schicht geleitet wird, oder alle Ausgaben der vorigen Schicht, wenn es sich nicht um die erste Schicht handelt. Diese Verbindungen sind gewichtet, um die stärke der Synaptischen Verknüpfung zwischen den Neuronen darzustellen. Diese Gewichte werden bei der Backpropagation angepasst. Im Netzwerk werden die Gewichte in einer Matrix gespeichert, hier heißt sie "weights". 

Um einen einzelnen Knoten k zu berechnen iteriert man über alle Inputs, multipliziert diese mit dem jeweiligen Gewicht zwischen dem Input und dem Knoten, also $w_{ik}$, und summiert die Ergebnisse:


$$Z_{Lk}=\sum_{i = 1}^{n}w_{ik}*x_i$$

Im Prinzip muss also nur der Term $w_{ik}*x_i$ im Bezug auf die Gewichte abgeleitet werden, um die Änderungsrate berechnen zu können, wenn die Gewichte angepasst werden.

$$\frac{\delta Z_L}{\delta w_L}=x_i$$

Wie wir sehen entspricht x einfach den Inputs aus der vorigen Schicht. Diese sollten also beim Forwardpass auf jeden Fall immer zwischengespeichert werden, um hier in der Backpropagagtion benutzt werden zu können. Dies wurde im letzten Kapitel schon vorbereitet.

Der nächste Term 
$$\frac{\delta a_L}{\delta Z_L}$$ Beschäftigt sich mit dem Einfluss von $Z_L$ auf die Ableitung von der Activation Funktion. Es gibt verschiedene Transferfunktionen $T(x)$, und zwei werden besonders häufig verwendet. Zum einen die Sigmoid Funktion, zum anderen ReLu. 
ReLu ist besonders leicht zu berechnen, und wird daher für schnelleres Lernen eingesetzt. Alle Werte unter 0 werden zu 0 Transformiert und ausgegeben, alle Werte über 0 werden so zurückgegeben, wie sie sind.

$$
T(x):=
\left\{
\begin{tabular}{l}
0 für $x<0$ \\
x für $x\geq 0$
\end{tabular}
\right\}
:=T_1(x)
$$

Die Ableitung davon ist auch denkbar einfach, Unter 0 hat die x keinen einfluss, über 0 hat es einen direkten Einfluss, also 1.

$$
T'(x):=
\left\{
\begin{tabular}{l}
0 für $x<0$ \\
1 für $x\geq 0$
\end{tabular}
\right\}
:=T'_1(x)
$$

Etwas aufwändiger ist die Sigmoid Funktion, die auch in diesem Netzwerk verwendet werden soll. Die Sigmoid Funktion sieht so aus:

$$\sigma (x)=\frac{1}{(1+e^{-x})}$$
Und ihre Ableitung:
$$\sigma '(x)=\sigma (x)(1-\sigma(x))$$

%TODO Es kann hier noch die Ableitung der Sigmoid erklärt werden, so wie Prof Lanz sich das gewünscht hat. Allerdings ist dies Extrem aufwändig, und nicht zu empfehlen...

Hier ist der Code für die Sigmoid Funktion und ihre Ableitung:
\begin{lstlisting}[language=Java] 
    //Die Sigmoid Funktion
    public double Sigmoid(double weightedInput) {
        return 1.0 / (1 + Math.exp(-weightedInput));
    }
    //Die Ableitung der Sigmoid Funktion
    public double SigmoidAbleitung(double weightedInput) {
        double activation = Sigmoid(weightedInput);
        return activation * (1.0 - activation);
    }
    
\end{lstlisting} 

Und hier ist die Relu Funktion mit ihrer Ableitung. Im Code sehr einfach umzusetzen:

\begin{lstlisting}[language=Java] 
    //Die ReLu Funktion
    public double ReLu(double weightedInput) {
        if (weightedInput <= 0)
        return 0.0;
    else
        return weightedInput;
    }
        
    //Die Ableitung der ReLu Funktion
    public double ReLuAbleitung(double weightedInput) {
        if (weightedInput <= 0)
            return 0.01; //Leak Value, um Tote bereiche zu vermeiden. Vermutlich bei Sigmoid kein Problem
        else
            return 1.0;
    }
\end{lstlisting} 

Nun kommen wir zum vorerst letzten Term:

$$\frac{\delta C_0}{\delta a_L}$$

gesucht ist die Ableitung der Cost oder Fehlerfunktion, im Bezug auf die Outputs der letzten Schicht im Netzwerk. Dies ist die Fehlerfunktion:

$$C_0 = (O_L - T)^2$$

Hierbei ist $O_L$ gleich $a_L$ des Netzwerkes.
Die Ableitung hier ist einfach:

$$\frac{\delta C_0}{\delta O_L} = 2(O_L - T)$$

Damit sind alle Terme der letzten Schicht im Netzwerk geklärt, und können eingesetzt werden.
Um im Code nachvollziehen zu können, welcher Wert was macht, nennen wir die Werte einfach genau so, wie sie geschrieben werden.


$$\frac{\delta Z_L}{\delta w_L} \rightarrow dZdw $$ \\
$$\frac{\delta a_L}{\delta Z_L} \rightarrow dadZ $$ \\
$$\frac{\delta C_0}{\delta a_L} \rightarrow dCda $$ \\

Nachdem die Namenskonvention geklärt ist, kann der Code erstellt werden:

\begin{lstlisting}[language=Java] 
    public void backPropagation2(double[] dCda) {
        double dZdw;
        double dadZ;
        double dCdw;

        for(int k=0; k<inLength; k++){
            for(int j=0; j<outLength; j++){
                dZdw = lastInput[k];
                dadZ = SigmoidAbleitung(lastZ[j]);

                dCdw = dZdw * dadZ * dCda[j];

                weights[k][j] -= dCdw*learnRate;
            }
        }
    }
\end{lstlisting} 

Um die Methode Modular zu halten, wird die Ableitung vom Error außerhalb der Methode berechnet, und als "dCda", also Ableitung der Cost Funktion im Bezug auf die Outputs der letzten Schicht, an die Methode übergeben. Dadurch wird die Backpropagation angestoßen. Als nächstes werden die Variablen aufgestellt. Das Ziel ist es, "dCdw", also die Cost Funktion im Bezug auf die Gewichte zu ermitteln. 
In einer verschachtelten Schleife über alle Gewichte werden die Variablen zunächst belegt.
Warum über alle Gewichte? Weil die Änderung für jedes Gewicht berechnet werden soll. 
"dZdw" Entspricht dem letzten Input aus der vorletzten Schicht. "dadZ" ist das Ergebnis der Ableitung der Transferfunktion, hier Sigmoid, im Bezug auf die gewichteten Inputs der vorletzten Schicht.
Um also das Ergebnis der Ableitung der Cost Funktion im Bezug auf die Gewichte der letzten Schicht im Netzwerk zu berechnen, müssen diese Zwischenergebnisse nur noch multipliziert werden. Das heißt die entsprechenden Werte von "dCda", die übergeben wurden, multipliziert mit "dZdw" und "dadZ".
Das Ergebnis dieser Rechnung ist die Steigung der Fehlerfunktion, an der Stelle, an der das jeweilige Gewicht eingesetzt wurde. Wenn die Steigung Positiv ist, sollte das Gewicht verringert werden, also abgezogen werden, um sich dem Fehlerminimum anzunähern.
Wenn die Steigung Negativ ist, liegt das Fehlerminimum voraus, also sollte das Gewicht vergrößert werden.
Wichtig an dieser Stelle ist noch zu beachten, dass die berechnete Änderungsrate zu groß ist, und mit der LearnRate multipliziert werden muss, bevor der Wert von den Gewichten abgezogen wird. Es könnte sonst dazu kommen, dass das Fehlerminimum übersprungen wird.

Dies ist die vollständige Berechnug der Anpassung der Gewichte in der letzten Schicht. Aber wie wird nun die vorletzte Schicht angepasst? und die Schicht davor?

Im Prinzip muss der Fehler weiter durch das Netzwerk zurückgereicht werden, und in jeder Schicht, die anpassbare Parameter hat, müssen diese Parameter so angepasst werden, wie sie für den Fehler verantwortlich waren.

Dies kann vollständig modular aufgebaut werden, sodass eine völlig variable Anzahl an Schichten möglich werden. Wenn man die Ableitung der Cost Funktion im Bezug auf die Gewichte der letzten Schicht, und die Ableitung der Cost Funktion im Bezug auf die Gewichte der Vorletzten Schicht miteinander vergleicht, so fällt auf, dass es Terme gibt, die zum Teil völlig gleich sind, dass es einen Term gibt der sich verändert, und dass es zwei neue Terme gibt, die sich von alten Termen nur darin unterscheiden, dass sie Inputs aus der Vorletzten, anstatt aus der letzten Schicht benötigen.

Diesmal wird die Änderungsrate der Cost Funktion $C$ gesucht, in Abhängigkeit von den Gewichten der vorletzten Schicht, $w_{(L-1)}$.

$$\frac{\delta C_0}{\delta w_{(L-1)}}=
\frac{\delta Z_{(L-1)}}{\delta w_{(L-1)}}*
\frac{\delta a_{(L-1)}}{\delta Z_{(L-1)}}*
\frac{\delta Z_L}{\delta a_{(L-1)}}*
\frac{\delta a_L}{\delta Z_L}*
\frac{\delta C_0}{\delta a_L}*
$$

Die letzten beiden Terme sind schon aus der vorherigen Rechnung bekannt.

$$\frac{\delta a_L}{\delta Z_L}$$
$$\frac{\delta C_0}{\delta a_L}$$

Damit gemeint sind die Ableitung der Cost Funktion, sowie die Ableitung der Activation Funktion. Diese können bereits in der Letzten Schicht verrechnet werden, und an die vorletzte Schicht übergeben werden. Außerdem kann die Ableitung des Dritten Terms ebenfalls in der letzten Schicht berechnet und übergeben werden. Dieser Unterscheidet sich von dem dritten Term in den Berechnungen für die letzte Schicht. Anstatt die Änderungsrate im Bezug auf Änderungen an den Gewichten, berechnet dieser Term im Bezug auf die Änderungen an den Inputs aus der vorherigen Schicht.

$$\frac{\delta Z_L}{\delta a_{(L-1)}}$$

Die Ableitung der Berechnung der Gewichteten Outputs der letzten Schicht, im Bezug auf die Inputs der vorletzten Schicht. Die Änderungsrate hängt hierbei völlig von den Gewichten der letzten Schicht ab, also gilt:

$$\frac{\delta Z_L}{\delta a_{(L-1)}} = w_L$$

Wenn diese drei Terme bereits in der Letzten Schicht berechnet werden, können sie ohne weiteres an die vorletzte Schicht übergeben werden. Nach diesem Prinzip können beliebig viele Schichten aneinander gereiht werden, und sich gegenseitig ihre berechneten Werte durchreichen. 

Die bisherigen Werte kann man zusammenfassen:

$$
\frac{\delta Z_L}{\delta a_{(L-1)}}*
\frac{\delta a_L}{\delta Z_L}*
\frac{\delta C_0}{\delta a_L}
= \frac{\delta C_0}{\delta a_{(L-1)}}
$$

$\frac{\delta C_0}{\delta a_{(L-1)}}$ kann einfach an die nächste Backpropagation Methode übergeben werden.

Dort, in der vorletzten Schicht, wird das gleiche getan, wie zuvor in der letzten Schicht. Die Eingabe, "dCda", wird mit diesen Termen verrechnet:

$$
\frac{\delta Z_{(L-1)}}{\delta w_{(L-1)}}*
\frac{\delta a_{(L-1)}}{\delta Z_{(L-1)}}*
\frac{\delta C_0}{\delta a_{(L-1)}}
$$

Diese Terme sind im Prinzip die gleichen wie zuvor, nur auf die aktuelle Schicht gemünzt. 

Um eine kleine Zusammenfassung zu schaffen:

Jede Schicht muss 3 Terme miteinander multiplizieren. 

Der erste Term beschreibt die ableitung der Cost Funktion im Bezug auf die Outputs der aktuellen Schicht. Bei der letzten Schicht im Netzwerk, also der ersten Schicht im Backpropagation Verfahren, ist das einfach die Ableitung der Cost Funktion, welche zum berechnen die Outputs des Netzwerks, und die erwarteten Werte der Inputs des Netzwerkes benötigt. In allesn weiteren Schichten handelt es sich dabei um errechnete Werte aus den anderen Schichten, welche übergeben werden. Ab hier werden sie im Code "dCd0" genannt, da der Name "dZda" anderweitig noch gebraucht wird.

Der zweite Term sieht in jeder Schicht gleich aus, es kommt hierbei lediglich auf die Inputs an. Es handelt sich um die Ableitung der Activation Funktion, im Bezug auf die gewichteten Inputs.

$$\frac{\delta a}{\delta Z}$$

Dieser Schritt wurde zuvor schon implementiert.
Übrig bleibt also nur der letzte Term. diesen gibt es in zwei Ausführungen, und zwar einmal um die Gewichte der aktuellen Schicht anzupassen, und einmal um die Werte zu berechnen, die an die nächste Schicht im Backpropagation Verfahren gereicht werden sollen.
Um die Gewichte anzupassen, benötigt man hierbei die Inputs aus der letzten Schicht, und auch dies wurde bereits Implementiert. Es bleibt nur noch die Berechnung für die nächste Schicht. Wie weiter oben schon festgestellt, handelt es sich dabei um die gewichte der Aktuellen Schicht. 
Nun zur Form. Es geht immer noch darum, die Fehler, die das Netzwerk gemacht hat, an die Schichten weiterzureichen. Daher muss ein Vektor erstellt werden, der den Outputs der vorherigen Schicht entspricht, und die Fehler enthält, die von der Schicht verursacht wurden.
Dieser Vektor wird nun "dCda" genannt, denn er soll immerhin die Änderungsraten enthalten, die durch die Ableitung der Cost Funktion im Bezug auf die Outputs "$a$" der vorherigen Schicht berechnet wurden. Eine weitere neue Variable ist der double "dZda", welcher schlichtweg das Gewicht enthält, welches gerade angepasst werden soll.

\begin{lstlisting}[language=Java]
    public void backPropagation(double[] dCd0) {
        double[] dCda = new double[inLength];
        double dZdw;
        double dadZ;
        double dCdw;
        double dZda;
\end{lstlisting} 
In der äußeren Schleife wird nun eine Variable "dCda\_sum" geführt. In dieser werden alle Änderungsraten der Cost Funktion im Bezug auf die Inputs der letzten Schicht aufsummiert. Dieser Wert wird für jeden Input der aktuellen Schicht erstellt und im Vektor "dCda" gespeichert.
\begin{lstlisting}[language=Java]  
        for(int k=0; k<inLength; k++){
            double dCda_sum = 0;

            for(int j=0; j<outLength; j++){
                dZdw = lastInput[k];
                dadZ = SigmoidAbleitung(lastZ[j]);
\end{lstlisting} 
In der inneren Schleife werden nun auch die entsprechenden Gewichte festgehalten. Wie zuvor werden nun die Änderungsraten für die aktuellen Gewichte berechnet und angewandt.
\begin{lstlisting}[language=Java]  
                dZda = weights[k][j]; 
                dCdw = dZdw * dadZ * dCd0[j];
                weights[k][j] -= dCdw*learnRate;
\end{lstlisting} 
Zuletzt wird aber die Änderungsrate der Cost Funktion im Bezug auf die Inputs der vorherigen Schicht berechnet. Statt dem letzten Input wird hier das Aktuelle Gewicht multipliziert, und zur variable "dCda\_sum" hinzugefügt.
\begin{lstlisting}[language=Java]              
                dCda_sum += dZda * dadZ * dCd0[j];
            }
            dCda[k] = dCda_sum;
        }
\end{lstlisting} 
Nach den Schleifen muss nur noch die Backpropagation Methode der vorherige Schicht aufgerufen werden, und dieser der Vector "dCda" übergeben werden.
\begin{lstlisting}[language=Java]   
        if(previousLayer!= null){
            previousLayer.backPropagation(dCda);
        }
    }
\end{lstlisting} 

Dieser Prozess muss zwar noch in den anderen Layern implementiert werden, aber auf diese elegante Weise kann die Backpropagation Methode umgesetzt werden. Wenn man das Netzwerk ausschließlich aus Fully Connected Layern aufbaut, funktionieren klassifikatorische Aufgaben schon ganz gut. Durch den Einsatz von Pooling Layern und Convolutional Layern sollte die Effizienz allerdings noch weiter gesteigert werden können.

\clearpage
\section{Pooling Layer}
Pooling Layer werden dazu verwendet, um das sogenannte Downsampling zu betreiben. Downsampling bedeutet einfach, dass eine geringere Auswahl an Daten weitergegeben werden.
In einem Netzwerk benutzt man eines dieser Verfahren, um die weiteren Schichten nur mit den nötigsten Daten zu belasten. Gerade in Anbetracht der Größe der Daten, die bei den Convolutional Layern entstehen, kann das viel Zeit sparen. Aber Hauptsächlich sorgt dies auch dafür, dass das Netzwerk weniger anfällig für Veränderungen der Daten wird. Leichte Veränderungen der Daten können für gravierende Änderungen sorgen, das heißt wenn ein Bild nicht korrekt Zentriert ist, oder wenn es um ein paar Grad gedreht wird, kommt ein Netzwerk schnell durcheinander.
Die Convolution Layer erstellen Feature Maps, in denen die Features allerdings auch die gleichen Positionen haben, wie in den Inputs. Dadurch können bei kleinen Veränderungen schon Fehler in den nächsten Schichten entstehen. Dem kann man durch das Downsampling entgegenwirken.

Auf eine Gewisse weise können die Daten bereits in den Convonlutional Layern "gedownsampelt" werden, wenn die Schrittgröße (Stride) beim anwenden der Filter Größer ist als 1.

Wie genau Funktioniert ein Pooling Layer dann? so wie bei den Convolutional Layern werden Filter eingesetzt. Diese sind aber kleiner, und funktionieren anders. Meist ist ein Filter hier nur 2x2 groß, und bei der Anwendung wird eine Schrittgröße von 2 verwendet. Die Filter überlappen die Felder nicht, die bereits behandelt wurden. 
Auf die Pixel, auf die der Filter angewandt wird, werden nun eine Pooling Operation durchgeführt. 

Zwei mögliche Pooling Operationen sind das Average Pooling und das Maximum Pooling. 
\begin{itemize}
  \item Das Average Pooling gibt den Durchschnitt aller Werte als Output zurück, während
  \item das Maximum Pooling nur den Größten Wert der betrachteten Werte zurückgibt.
\end{itemize}
Es gibt noch weitere, wie zum Beispiel das Globale Pooling, bei dem die Gesammte Feature Map auf einen einzigen Wert reduziert wird. Dadurch soll auf eine möglichst Aggressive Art festgestellt werden, ob ein bestimmtes Feature überhaupt in der Feature Map vorkommt. Je nach Anwendungsfall kann auch diese Methode Erfolg bringen.

Zunächste wird die Maximum Pooling Layer betrachtet.
genau wie bei den Convolutional Layern, wird hier eine StepSize verwendet. Zwar ändert sich diese in den meisten Fällen nicht, aber es ist gut, die Flexibilität zu haben.
Die windowSize legt fest, welche Dimensionen der Filter haben soll.
\\Außerdem ist es hilfreich, wenn die input Parameter auch gespeichert werden, damit gemeint sind input length, input rows und input columns, also die menge an Bilder, zusammen mit den Zeilen und Reihen die diese Bilder haben.

\begin{lstlisting}[language=Java]
public class MaxPoolLayer extends Layer {

    private int stepSize;
    private int windowSize;

    private int inLength;
    private int inRows;
    private int inCols;
\end{lstlisting} 

\subsection{Forward Propagation im Pooling Layer}
Wie oben beschrieben, wird hier ein kleiner Filter benutzt, der über die Input Bilder gleitet, und entweder den maximalen Wert, oder den Durchschnittswert zurückgibt. 

%TODO Bild einfügen

Zunächst wird eine Methode benötigt, die den Filter darstellt, und eine Feature Map durchläuft. 

\begin{lstlisting}[language=Java]
 public double[][] pool(double[][] input){
 		//Die Output Dimensionen müssen berechnet werden
        double[][] output = new double[getOutputRows()][getOutputCols()];
        //zwei Schleifen um über den Input zu Iterieren
        for(int r=0; r<getOutputRows(); r+=stepSize){
            for(int c=0; c<getOutputCols(); c+=stepSize){
                double max = 0.0;
                //Zwei Schleifen um das Maximum im Fenster des Filters zu finden
                for(int x=0; x<windowSize; x++){
                    for(int y=0; y<windowSize; y++){
                        if(max<input[r+x][c+y]){
                            max=input[r+x][c+y];
                        }
                    }
                }
                output[r][c] = max;
            }
        }
        return output;
    }
\end{lstlisting}
Alternativ kann natürlich auch der Durchschnitt errechnet und ausgegeben werden. Dazu sind keine Großen Anpassungen nötig:
\begin{lstlisting}[language=Java]
 public double[][] pool(double[][] input){
 		//Die Output Dimensionen müssen berechnet werden
        double[][] output = new double[getOutputRows()][getOutputCols()];
        //zwei Schleifen um über den Input zu Iterieren
        for(int r=0; r<getOutputRows(); r+=stepSize){
            for(int c=0; c<getOutputCols(); c+=stepSize){
                double average = 0.0;
                //Zwei Schleifen um die Werte im Fenster des Filters zu addieren
                for(int x=0; x<windowSize; x++){
                    for(int y=0; y<windowSize; y++){
                    	average+=input[r+x][c+y];
                    }
                }
                //Der Durchschnitt muss natürlich noch durch die menge der im Filter Fenster enthaltenen Pixel geteilt werden
                output[r][c] = average/(windowSize*windowSize);
            }
        }
        return output;
    }
\end{lstlisting}
Im Code wurden die Methoden getOutputRows und getOutputCols schon verwendet, also müssen diese auch noch Implementiert werden. Die Formel dazu sieht folgendermaßen [2] aus:
$$H_{out} = floor(1 + (H - pool\_height)/stride)$$
$$W_{out} = floor(1 + (W - pool\_ width)/stride)$$

$H_{out}$ und $W_{out}$ entsprechen den Dimensionen des output Fensters. 

Und im Code werden diese so umgesetzt:

\begin{lstlisting}[language=Java]
    public int getOutputRows() {
        return (inRows - windowSize) / stepSize + 1;
    }

    public int getOutputCols() {
        return (inCols - windowSize) / stepSize + 1;
    }
\end{lstlisting}

\subsection{Backpropagation im Pooling Layer}
Für die Backpropagation in einem Pooling Layer müssen keine gewichte oder Biases angepasst werden. Denn diese gibt es hier nicht. Stattdessen muss der Fehler aber trotzdem auf einen der Inputs zurückgeführt werden, das heißt zum Beispiel, dass beim Max Pooling aus jedem von dem Filter Fenster betrachteten Gebiet der Maximale Wert für den Fehler verantwortlich war, und die anderen Werte keine Verantwortung tragen. 

%TODO Bild einfügen

Am besten gelingt dies, indem die Positionen der Maximal Werte gespeichert werden.
Dazu sollten erst neuen Instanzvariablen angelegt werden:


\begin{lstlisting}[language=Java]
    List<int[][]> lastMaxRow;
    List<int[][]> lastMaxCol; 
\end{lstlisting}

Zwei Listen, welche 2-Dimensionale Arrays enthalten, jeweils eine liste für die Koordinate der X und eine für die Y Achse.
Danach müssen diese Initialisiert werden, und zwar in der "maxPoolForwardPass" Methode. Das stellt sicher, dass sie initialisiert werden, bevor das pooling beginnt:

\begin{lstlisting}[language=Java]
    public List<double[][]> maxPoolForwardPass(List<double[][]> input) {
        //Initialisierung der lastMaxRow und Col, in denen die Position der Maximalen Werte gespeichert werden
        lastMaxRow = new ArrayList<>();
        lastMaxCol = new ArrayList<>();
\end{lstlisting}

Um die Werte dann zu speichern, müssen diese während der pooling Operation gespeichert werden.
Dazu können zwei 2-Dimensionale Integer Arrays verwendet werden, welche mit den gleichen Maßen initialisiert werden, wie die Outputs. Das heißt, dass für jeden Output die X und Y Koordinate im dazugehörigen lastMax-Array ein entsprechender Platz vorhanden ist.

\begin{lstlisting}[language=Java]
public double[][] pool(double[][] input) {
        double[][] output = new double[getOutputRows()][getOutputCols()];

        int[][] maxRows = new int[getOutputRows()][getOutputCols()];
        int[][] maxCols = new int[getOutputRows()][getOutputCols()];   
\end{lstlisting}
für den Fall, das kein maximum über 0 gefunden werden konnnte, sollten Koordinaten trotzdem markiert werden, darum werden die alle Felder zuerst auf -1 gesetzt:
\begin{lstlisting}[language=Java]
        for (int r = 0; r < getOutputRows(); r += stepSize) {
            for (int c = 0; c < getOutputCols(); c += stepSize) {
                double max = 0.0;

                maxRows[r][c] = -1;
                maxCols[r][c] = -1;
\end{lstlisting}
In der inneren Schleife müssen die Koordinaten natürlich auch gespeichert werden, wenn ein neues Maximum im Fenster gefunden wurde:
\begin{lstlisting}[language=Java]
                for (int x = 0; x < windowSize; x++) {
                    for (int y = 0; y < windowSize; y++) {
                        if (max < input[r + x][c + y]) {
                            max = input[r + x][c + y];
//Koordinaten des Maximalen Wertes werden in den dafür vorgesehenen Arrays gespeichert
                            maxRows[r][c] = r + x;
                            maxCols[r][c] = c + y;
                        }
                    }
                }
                output[r][c] = max;
            }
        }
\end{lstlisting}
zuletzt müssen die Arrays, welche die Koordinaten enthalten noch den Listen hinzugefügt werden, die am Anfang Initialisiert wurden:
\begin{lstlisting}[language=Java]
        lastMaxRow.add(maxRows);
        lastMaxCol.add(maxCols);
        return output;
    }
\end{lstlisting}

Die eigentliche Umsetzung der Backpropagation findet in der "backPropagation" Methode statt. Der Grundgedanke ist der, dass nur der Maximalwert zum Fehler beigetragen hat, und daher auch nur dieser Wert angepasst werden muss. Also Erstellt man eine Fehlermatrix, die überall nur 0 enthält, außer an den Stellen, von denen die Maximalwerte genommen wurden. Da werden die Fehlerwerte eingetragen, und dann, da es hier keinerlei Gewichte oder Biases gibt, wird diese Fehlermatrix dann an die nächste Schicht weitergegeben.
Zuerst muss eine Liste mit den Fehlermatrizen erstellt und initialisiert werden und es wird ein Zähler benötigt, um über alle vorher angelegten Koordinaten-Matrizen zu iterieren, welche die Positionen der Maximalwerte enthalten.
\begin{lstlisting}[language=Java]
    public void backPropagation(List<double[][]> dLdO) {
        List<double[][]> dXdL = new ArrayList<>();
        int l=0;
\end{lstlisting}
Dann wird über alle eingehenden Fehlermatrizen iterriert, um die jeweilige Fehlermatrize zu erstellen, die an die nächste Schicht weitergegeben wird. letztere muss zunächst initialisiert werden.  
\begin{lstlisting}[language=Java]
        for(double[][] array : dLdO){
            double[][] error = new double[inRows][inCols];
\end{lstlisting}
Dann muss die eingehende Fehlermatrix durchiteriert werden. für jeden eingehenden wert wird die Position des verantwortlichen Maximalwerts ermittelt. In der entstehenden Fehlermatrix wird der eingehende fehler dann an der jeweiligen Position hinzugefügt. Wichtig ist, dass der Wert zu den bestehenden Werten hinzugefügt wird. meistens überlappen sich die betrachteten fenster in der Pooling Phase nicht, aber falls doch, kann ein ein Wert in mehreren Fenstern der Maximalwert sein, daher ist dieser wert dann auch sozusagen für mehrere Fehler verantwortlich. Das wird dadurch ausgedrückt, dass der Fehlerwert dann aufaddiert wird.
\begin{lstlisting}[language=Java]
            for(int r=0; r<getOutputRows(); r++){
                for(int c=0; c<getOutputCols(); c++){
                    int max_i = lastMaxRow.get(l)[r][c];
                    int max_j = lastMaxCol.get(l)[r][c];

                    if(max_i != -1){
                        error[max_i][max_j] += array[r][c];
                    }
                }
            }
\end{lstlisting}
Zuletzt müssen die entstandenen Fehlermatrizen nur noch der liste hinzugefügt werden, welche dann an die nächste Schicht weitergegeben wird.  
\begin{lstlisting}[language=Java]
            dXdL.add(error);
            l++;
        }
        if(previousLayer != null){
            previousLayer.backPropagation(dXdL);
        }
    }
\end{lstlisting}

Für den Fall, dass die eingehenden Fehler keine liste, sondern eine einfaches Array ist, also zum Beispiel weil die nächste Schicht eine Fully Connected Layer ist, erstellt man noch eine "backPropagation" Methode:

\begin{lstlisting}[language=Java]
    public void backPropagation(double[] dLdO) {
        List<double[][]> matrixList = vectorToMatrix(dLdO, getOutputLength(), getOutputRows(), getOutputCols());
        backPropagation(matrixList);
    }
\end{lstlisting}

\cleardoublepage
\section{Convolutional Layer}
Diese Kapitel beschäftigt sich mit dem Namensgeber des gesamten Netzwerks: Das convolutional Layer. 
In dieser Schicht geht es darum, bestimmte Features zu erkennen, und diese in einer sogenannten Feature Map zu speichern und weiterzugeben. Features sind bestimmte Merkmale in einem Bild. Je nachdem, welches merkmal gesucht wird, können dabei senkrechte oder waagerechte Kanten erkannt werden, aber auch Kurven, und andere komplexere Merkmale. Abhängig davon, wie groß das Netzwerk ist, können auch sehr spezifische Merkmale gesucht werden, wie zum Beispiel ganze Autoreifen. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.27]{./Images/BA_003_tensorflow-keras-cnn-hierarchical-structure.png}
\caption{Tiefe der Abstraktion von Merkmalen [3]}
\label{Tiefe der Abstraktion von Merkmalen [3]}
\end{figure}

Diese Merkmale sind hierarchisch aufgebaut, das heißt das auf den vorderen Schichten nach Simpleren Formen gesucht wird, und auf den späteren Schichten werden diese Merkmale zu Komplexen Merkmalen zusammengesetzt.

So wie bei den Pooling Layern, werden in den Convolutional Layern Filter eingesetzt, die über das Input Bild gleiten, und eine bestimmte Operation ausführen. Im Gegensatz zu den Pooling Layern, können die Convolutional Layer mehrere Filter besitzen. Dies kann zu Großen mengen an Daten führen, denn jedes Input Bild wird mit jedem Filter verrechnet, und sorgt daher für eine weitere Feature Map. Also die Anzahl der Input Bilder, multipliziert mit der Anzahl der Filter, ergibt die menge der Feature Maps, die an die nächste Schicht weitergegeben werden.

\textbf{Wie Funktioniert die Convolution Operation?}

Die Operation besteht aus einer Rechenoperation zwischen den Filtern, und der Fläche, über welche sie gelegt werden. Ein Filter besteht aus einer Matrix, welche häufig 3x3 oder 5x5 Felder groß ist. 
Ein Filter wird über das Eingangsbild geschoben, so wie bereits bei den Pooling Layern. Allerdings werden hierbei alle Werte mit den Werten des Filters multipliziert, an den Stellen, an denen sie übereinander liegen. Diese Werte werden addiert, und in einer Feature Map gespeichert.
Genau genommen ist diese Operation eine Kreuzkorrelation. Eine Convolution, im Deutschen "Faltung" genannt, wäre eine Kreuzkorrelation, bei der die Filter noch um 180° gedreht werden müssten. Dies ist allerdings nicht nötig für das Netzwerk. Der Name Convolutional Network ist geblieben, aber statt der eigentlichen Faltung wir die Kreuzkorrelation verwendet.
Der Filter kann dabei ganz weit außen starten, oder innerhalb der grenzen des Eingangsbildes. Wenn der Filter ganz weit außen startet, so dass nur ein einziges Feld mit dem Eingangsbild überlappt, dann nennt man das eine "Full Cross-Correlation". Wenn der Filter ganz in der Oberen Linken Ecke startet, dabei aber bereits beim ersten Schritt alle Felder des Filters innerhalb der grenzen des Eingangsbildes befinden, dann nennt man das "Valid Cross-Correlation".
In diesem Netzwerk wird die Valid Cross-Correlation verwendet. Die Größe der entstehenden Feature Map hängt ebenfalls davon ab, welche Cross-Correlation verwendet wird. 
Bei der Full Cross-Correlation wird außerhalb der Matrix angefangen. Das bedeutet, dass mehr Schritte benötigt werden, um durch eine Reihe zu iterieren, und daher entstehen auch mehr Einträge in der Feature Map.

% Done Hier muss noch ein Bild hin welches die Full Cross-Correlation erklärt
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{./Images/Full_Correlation_004.jpg}
\caption{Full Cross-Correlation}
\label{Full Cross-Correlation}
\end{figure}
 
Die Valid Cross-Correlation hingegen beweg sich nur in den Grenzen des Eingangsbildes, daher entstehen weniger Einträge in die Feature Map.

% Done Hier muss noch ein Bild hin welches die Valid Cross-Correlation erklärt
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{./Images/Valid_Correlation_005.jpg}
\caption{Valid Cross-Correlation}
\label{Valid Cross-Correlation}
\end{figure}

Die Berechnung der Breite und Höhe einer entstehenden Feature Map sind genauso aufgebaut wie zuvor bei den Pool Layern:

$$H_{out} = (H - filter\_height)/stride + 1$$
$$W_{out} = (W - filter\_ width)/stride + 1$$


% TODO Hier müssen mehr erklärungen hin zu der Funktionsweise der Schicht










\cleardoublepage
\subsection{Klassenaufbau der Convolutional Layer}
Grundlegend braucht diese Schicht Filter. Die Filter werden von zwei Parametern gebildet, und zwar "filterSize" und "numFilters". Die Größe der Filter wird dabei von "filterSize" festgelegt, und "numFilters" beschreibt die Anzahl an Filtern. Wir gehen davon aus, dass die Filter immer Quadratisch sind, daher reicht ein Wert um die Größe zu beschreiben.

Darüber hinaus wird wie bei den Pool Layern zuvor, wieder Schritt Größen, also "stepSize", gebraucht. Diese entscheiden, wie viele Pixel der Filter bei einem Schritt überspringt. Wenn diese Größer angelegt werden, werden die Feature maps dementsprechend kleiner, allerdings kann das dazu führen, dass Features nicht erkannt und weiterverarbeitet werden. 

Die Restlichen Werte die übergeben werden haben mit der Verarbeitung der eingangs- und Ausgangsbildern zu tun.

Wichtig ist, dass genau wie in den Fully Connected Layern die anpassbaren Werte nicht mit 0 als Startwert initiiert werden, sondern mit zufällig generierten Zahlen. Ansonsten würden die Anpassungen auch immer gleich aussehen. Die Werte, die in dieser Schicht trainiert werden können, sind die Werte in den Filtern.

Hier ist die Constructor Methode der Klasse "ConvolutionLayer":

\begin{lstlisting}[language=Java]
public ConvolutionLayer(int filterSize, int stepSize, int inLength, int inRows, int inCols, int numFilters, double learnRate) {
        this.filterSize = filterSize;
        this.stepSize = stepSize;
        this.inLength = inLength;
        this.inRows = inRows;
        this.inCols = inCols;
        this.learnRate = learnRate;

        generateRandomFilters(numFilters);
    }
\end{lstlisting}

Und in der Methode "generateRandomFilters" werden die Filter generiert, und mit Zufallszahlen initiiert. Dabei werden die Filter entsprechend der "filterSize" angelegt und die Liste, welche die Filter enthält ist so groß, wie durch "numFilters" angegeben.

\begin{lstlisting}[language=Java]
private void generateRandomFilters(int numFilters) {
        List<double[][]> filters = new ArrayList<>();
        Random random = new Random();

        for (int n = 0; n < numFilters; n++) {
            double[][] newFilter = new double[filterSize][filterSize];

            for (int i = 0; i < filterSize; i++) {
                for (int j = 0; j < filterSize; j++) {
                    double value = random.nextGaussian();
                    newFilter[i][j] = value;
                }
            }
            filters.add(newFilter);
        }
        this.filters = filters;
    }
\end{lstlisting}

Die entstandenen Filter werden in einer Liste gespeichert. Die Objektvariablen sehen ähnlich wie in den anderen Schichten aus. Die Liste "filters" enthält unsere Filter, inLength entspricht der zusammengefassten Menge aller Inputs aus der vorherigen Schicht. "inRows" und "inCols" beschreiben wieder die Abmaßen der Input Bilder. Auch die Learnrate wird in dieser Schicht, so wie in der Fully Connected Schicht berücksichtigt.

Für die Backpropagation müssen auch hier wieder die Inputs während dem Forwardpass zwischengespeichert werden. Die Liste "lastInput" erfüllt diesen Zweck.

\begin{lstlisting}[language=Java]

public class ConvolutionLayer extends Layer {

    private List<double[][]> filters;
    private int filterSize;
    private int stepSize;

    private int inLength;
    private int inRows;
    private int inCols;
    private double learnRate;

    private List<double[][]> lastInput;

\end{lstlisting}


%\cleardoublepage
\subsection{Forward Propagation im Convolutional Layer}

Die Wichtigste Operation im Forwardpass ist die anwendung der Cross Correlation. Dazu benötigen wir zuerst eine Methode, welche diese Operation auf jedem Input Bild und für jeden Filter anwenden kann. 
Wir erstellen die Methode "convolve". Die Übergabeparameter sind ein Bild, auf dem die operation angewendet werden soll, ein Filter, der verwendet werden soll und die Schrittweite, wie viele Pixel übersprungen werden sollen:

\begin{lstlisting}[language=Java]
private double[][] convolve(double[][] input, double[][] filter, int stepSize) {
\end{lstlisting}

Als erstes können wir berechnen, wie groß die Feature Map wird, die entstehe wird. Die Formel dazu wurde oben bereits erläutert. Die Größe der Filter und die Schrittweite müssen dabei berücksichtigt werden. Die Feature Map kann dann als 2 Dimensionales Array initialisiert werden:

\begin{lstlisting}[language=Java]
int outRows = (input.length - filter.length) / stepSize + 1;
int outCols = (input[0].length - filter[0].length) / stepSize + 1;

double[][] output = new double[outRows][outCols];
\end{lstlisting}

Als nächstes legen wir zur besseren Lesbarkeit zwei Parameter an, welche die Länge und Größe des Input Bildes beinhalten:

\begin{lstlisting}[language=Java]
int inRows = input.length;
int inCols = input[0].length;
\end{lstlisting}

Und wir benötigen auch die Maße des Filters:

\begin{lstlisting}[language=Java]
int fRows = filter.length;
int fCols = filter[0].length;
\end{lstlisting}

Nun müssen wir über das Input Bild iterieren, und bei jedem Schritt über den Filter iterieren. Dazu verwenden wir 4 Schleifen. Die Äußeren zwei Schleifen wandern über das Bild, und die inneren Schleifen wandern über den Filter. 

Um den Überblick zu behalten, an welche Stelle der jeweils berechnete Wert in dei Feature Map geschrieben wird, werden die zwei Nummern am Anfang initiiert. Sie enthalten die Koordinate auf der Feature Map, die gerade beschrieben werden soll.

Die Ersten zwei Schleifen iterieren über das input Bild. Der jeweilige Schleifenindex enthält die Koordinate, an der der Filter zur Zeit angesetzt werden soll. Dabei soll der Filter von der ersten Reihe oder Zeile, bis zur letzten laufen, allerdings soll der Filter die Grenzen des Bildes nicht überschriten. Daher wird von der länge des Bildes die Länge des Filters abgezogen, und dieser Wert ist der letzte, bis zu dem der Filter angelegt wird. Der jeweilige Schleifenindex wird bei jeder iteration um die Schrittlänge erweitert. auf diese weise läuft der Filter genau wie gewünscht über das Bild.

Die Feature Map Koordinaten werden Parallel zu den äußeren Schleifen stetig angehoben, allerdings immer nur um eins, da die Feature Map mit jedem Sprung der Filter einen Wert erhält.

\begin{lstlisting}[language=Java]
int featureRow = 0;
int featureCol;
for (int i = 0; i <= inRows - fRows; i += stepSize) {
    featureCol = 0;
    for (int j = 0; j <= inCols - fCols; j += stepSize) {
\end{lstlisting}

Bevor es in die inneren Schleifen geht, muss die Summe initialisiert werden, die später in die Felder der Feature Map eingetragen werden. Die Inneren zwei schleifen iterieren dann über alle Felder des Filters. Um die Position des Feldes auf dem Input Bild zu bestimmen, werden die Werte "inputRowIndex" und "inputColIndex" verwendet, welche lediglich aus der Summe zwischen dem Index der Äußeren Zeilen- oder Reihenschleife, und der Inneren- Zeilen oder Reihenschleife bestehen. Die Position des Filters bestehen aus den Schleifen Indizes. Der Wert aus dem Input Bild und der Wert aus dem Filter werden multipliziert, und auf die den "sum" Wert aufaddiert. Sobald alle Felder des Filters abgewandert sind, wird der sum Wert an die entsprechende Stelle in der Feature Map geschrieben.

\begin{lstlisting}[language=Java]
        double sum = 0.0;
        // Hier werden Die Filter Eingesetzt
        for (int x = 0; x < fRows; x++) {
            for (int y = 0; y < fCols; y++) {
                int inputRowIndex = i + x;
                int inputColIndex = j + y;
                double value = filter[x][y] * input[inputRowIndex][inputColIndex];
                sum += value;
            }
        }
        featureMap[featureRow][featureCol] = sum;
        featureCol++;
    }
    featureRow++;
}
return featureMap;  
\end{lstlisting}

Die Feature Map wird dann zurück gegeben. Dies muss allerdings nicht nur für jedes bild, sondern auch für jeden Filter gemacht werden. Dazu schreiben wir die methode "convolutionForwardPass". Diese benötigt eine Liste an input Bildern, und gibt eine Liste an Feature Maps zurück:

\begin{lstlisting}[language=Java]
public List<double[][]> convolutionForwardPass(List<double[][]> list) {
    lastInput = list;
    List<double[][]> featureMaps = new ArrayList<>();

    for (int m = 0; m < list.size(); m++) {
        for (double[][] filter : filters) {
            featureMaps.add(convolve(list.get(m), filter, stepSize));
        }
    }
    return featureMaps;
}
\end{lstlisting}

Wichtig hierbei ist zu beachten, dass die Input Bilder in dem Objekt Parameter "lastInput" gespeichert werden. Diese werden für die Backpropagation benötigt.


%\cleardoublepage
\subsection{Backpropagation im Convolutional Layer}
Das Konzept der Backpropagation funktioniert im Prinziep so wie zuvor bei den Fully Connected Layern. Jedoch wurde zuvor die Gewichte angepasst, hier, in den Convolutional Layern, werden stattdessen die Filter angepasst. Wie zuvor besprochen, erhofft man sich davon, dass die Filter bestimmte Features erlernen, und diese dann erkennen können.
Ebenfalls genau wie zuvor, müssen wir heraus finden, wie viel ein jeder Eintrag im Filter zu dem entsatandenen Fehler beigetragen hat. Dazu kann eine Ableitung der Forward Pass Funktion genutzt werden. Anhand der Steigung kann dann abgelesene werden, in welche Richtung die Filter angepasst werden müssen. Dieser Prozess ist aber etwas komplizierter, als in den Fully Connected Schichten. Jeder eintrag im Filter hat nicht auf alle Felder in einem Input Bild Einfluss. Zum einen wird bei der Valid Cross Correlation nicht jeder Eintrag des Filters über alle Pixel des Bildes gezogen, sondern der Filter bleibt an den Grenzen des Bildes stehen. Noch komplizierter wird es, wenn der Filter eine Schrittgröße über größer als eins hat. Dann entstehen Lücken, über die der jeweilige Eintrag im Filter Springt. All dass muss beachtet werden. 

Wir sehen uns zuerst ein Beispiel für einen Forwardpass an:

\begin{figure}[H]
\centering
\includegraphics[scale=0.50]{./Images/TemporaryPlaceholders/Bildschirmfoto vom 2024-05-20 15-33-37.png}
\caption{Beispiel für Forwardpass}
\label{Beispiel für Forwardpass}
\end{figure}

Das Input Bild hat eine Größe von 5x5 Pixeln, der Filter hat eine Größe von 2x2, und dadurch entsteht ein Output von 2x2, wenn die Schrittgröße 2 Pixel beträgt. 
Wenn nun der Filter auf die erste Stelle gesetzt wird, dann können wir die Rechnung für die Anpassung des ersten Eintrags in der Feature Map anlegen. Anders gesagt, diese Rechnung ist für das Ergebnis in der Feature Map verantwortlich:

%TODO Der Text passt nicht zum Bild, Bild muss angepasst werden

\begin{figure}[H]
\centering
\includegraphics[scale=0.50]{./Images/TemporaryPlaceholders/Bildschirmfoto vom 2024-05-20 15-40-51.png}
\caption{Forwardpass ausrechnen}
\label{Forwardpass ausrechnen}
\end{figure}

Um nun auszurechnen, wie der Filter angepasst werden sollte, muss die Ableitung der Funktion errechnet werden, im Bezug auf den Eintrag im Filter. Für diese Formel schreiben wir:
$$\frac{dC}{dF_{11}}$$

Wobei $dC$ die Fehlermenge ist, die wir aus der nächsten Schicht oder von der Cost funktion erhalten, und $dF_{11}$ den Eintrag im Filter in erster Reihe und Zeile beschreibt.

Zuerst nutzen wir die Kettenregel um das aufzuschlüsseln. So wie zuvor, wissen wir dass die Costfunktion von den Outputs abhängt, die das Netzwerk gibt. Und die Outputs werden direkt von den Filtern beinflusst. Also haben wir zwei Terme, die Cost FUnktion in abhängigkeit von den Outputs $\frac{dC} {dO} $ und die Outputs in Abhängigkeit zu den Filtern $ \frac{dO} {dF_{11}}$.
$$\frac{dC}{dF_{11}} = \frac{dC} {dO} \frac{dO} {dF_{11}}$$

Allerdings müssen diese weiter aufgeschlüsselt werden. Der Filter hat immerhin Einfluss auf mehrere Outputs, welche wiederum Einfluss auf mehrere Ergebnisse der Cost Funktion haben. Dazu überlegen wir uns einmal, was genau hereingereicht wird. Die Fehler, die z.B. aus einer Fully Connected Schicht hereingereicht werden, entsprechen einer langen Liste mit dem gleichen Format der Inputs, welche jene Schicht erhalten hat. Da wir wissen, auf welche weise wir die Outputs beim Forwardpass aus mehreren 2 Dimensionalen Bildern in ein einziges Array Sortieren, das heißt die Ausgabe wird geflattet, können wir diese Formatierung sozusagen auch rückgängig machen. Solange sich die nächste Schicht an die Konventionen hält, müssten wir in der Lage sein, ein Array an Errors, welches wir von der nächsten Schicht erhalten, in eine Anzahl an Arrays zu formatieren, welche den Maßen der Feature Maps entspricht.
Wir haben dann also eine Reihe an Feature Cost Maps, welche die Abweichungen enthalten, die von den Filtern verursacht wurden. Hier ein Beispiel:

%TODO Dieses Bild selbst malen, dabei beachten das dL bei mir dC heißt, und dO kann so bleiben denke ich

\begin{figure}[H]
\centering
\includegraphics[scale=0.80]{./Images/TemporaryPlaceholders/Bildschirmfoto vom 2024-05-20 17-15-41.png}
\caption{Cost inputs}
\label{Cost inputs}
\end{figure}

Gehen wir zuerst auf die einzelnen Terme ein. $dC$ ist das Ergebnis der Cost Funktion, so wie zuvor. $dO_{ij}$ entspricht dem Output, der als Eingabe für die Cost Funktion zuständig war.

Mit diesem Filter, der 4 Elemente enthält, entstehen dann also 4 Terme, welche die Formel oben weiter aufschlüsseln:

$$
\frac{dC}{dF_{11}} = 
\frac{dC} {dO} \frac{dO} {dF_{11}}= 
\frac{dC} {dO_{11}} \frac{dO_{11}} {dF_{11}}+
\frac{dC} {dO_{12}} \frac{dO_{12}} {dF_{11}}+
\frac{dC} {dO_{21}} \frac{dO_{21}} {dF_{11}}+
\frac{dC} {dO_{22}} \frac{dO_{22}} {dF_{11}}
$$

$\frac{dO_{11}} {dF_{11}}$ wollen wir zuerat ableiten. Dazu sehen wir uns an, wie die Rechnung der Outputs zu stande kommt:

$$
O_{11} = X_{11}F_{11}+X_{12}F_{12}+X_{13}F_{13}+X_{21}F_{21}+X_{22}F_{22}+X_{23}F_{23}+X_{31}F_{31}+X_{32}F_{32}+X_{33}F_{33}
$$

Wenn wir nun nach $F_{11}$ ableiten, dann stellt sich heraus, dass nur ein einziger Wert übrig bleibt:

$$\frac{dO_{11}} {dF_{11}} = X_{11}$$

Genau so sieht es mit den anderen Ableitungen der Output Funktion aus, hier noch ein Beispiel:

$$
O_{12} = X_{13}F_{11}+X_{14}F_{12}+X_{15}F_{13}+X_{23}F_{21}+X_{24}F_{22}+X_{25}F_{23}+X_{33}F_{31}+X_{34}F_{32}+X_{35}F_{33}
$$

$$\frac{dO_{12}} {dF_{11}} = X_{13}$$

Die Andern zwei Ableitungen sind


$$\frac{dO_{21}} {dF_{11}} = X_{31}$$

$$\frac{dO_{22}} {dF_{11}} = X_{33}$$

Wir können das zur bessernen Lessbarkeit eimal in die Lange Formel von vorhin einsetzten:

$$
\frac{dC}{dF_{11}} = 
\frac{dC} {dO_{11}} X_{11}+
\frac{dC} {dO_{12}} X_{13}+
\frac{dC} {dO_{21}} X_{31}+
\frac{dC} {dO_{22}} X_{33}
$$

Und einmal mit einer Grafik:

%TODO Das Bild muss noch angepasst werden, die Formel steht ja schon oben drüber, muss also weg, Reihenfolge verändern
\begin{figure}[H]
\centering
\includegraphics[scale=0.50]{./Images/TemporaryPlaceholders/Fehlerrückverfolgung auf Filtern.png}
\caption{Fehlerrückverfolgung zu einem Filter}
\label{Fehlerrückverfolgung zu einem Filter v1}
\end{figure}

Das die einzelnen Werte auf dem Input Bild jeweils einen Schritt auseinander liegen, liegt daran, dass die Schrittgröße in diesem Beispiel bei 2 liegt. Dadurch wird jeweils ein Pixel übersprungen. Hätten wir hier eine Schrittgröße von 1, dann lägen die Werte beieinander. Oder wenn die Schrittgröße weiter wäre, z.B. bei 3 oder mehr, dann lägen 2 oder mehr Pixel dazwischen.

Die Zweite Änderungsrate die wir berechnen wolen, ist $\frac{dC}{dF_{12}}$. 


$$
\frac{dC}{dF_{12}} = 
\frac{dC} {dO_{11}} X_{12}+
\frac{dC} {dO_{12}} X_{14}+
\frac{dC} {dO_{21}} X_{32}+
\frac{dC} {dO_{22}} X_{34}
$$

%TODO Das Bild muss noch angepasst werden, Reihenfolge verändern
\begin{figure}[H]
\centering
\includegraphics[scale=0.50]{./Images/TemporaryPlaceholders/Fehlerrückverfolgung auf Filtern_2.png}
\caption{Fehlerrückverfolgung zu einem Filter}
\label{Fehlerrückverfolgung zu einem Filter v2}
\end{figure}

Auch hier wird wieder der Abstand zwischen den Werten eingehalten. Dieses Muster kann für das Netzwerk genutzt werden. 

Das Konzept sieht folgendermaßen aus: Wir erstellen ein Hilfs-Array, welches die Form eines Filters hat, und die Fehler, also die Werte $\frac{dC} {dO}$ so angeordnet enthält, dass sie an der Richtigen Stelle mit den Werten des input Bildes verrechnet werden, wenn wir die Convolution Methode Anwenden. Auf diese Weise stellen wir Sicher, dass für den jeweiligen Eintrag im Filter, der für die Fehler verantwortlich war, genau die Werte im Input Bild verwendet werden, mit denen er auch wirklich zu tun hatte.

Diese Methode nennen wir jetzt "spaceArray". Sie erhällt unsere Fehler Matrix, und wandelt diese mithilfe der in der Schicht gespeicherten "stepSize" in eine Array um, das wir oben beschrieben haben.

%TODO Es kann noch eine Entscheidung getroffen werden, ob dieser Code Tiefer erklärt werden soll
\begin{lstlisting}[language=Java]
    public double[][] spaceArray(double[][] input) {
        if (stepSize == 1) {
            return input;
        }

        int outRows = (input.length - 1) * stepSize + 1;
        int outCols = (input[0].length - 1) * stepSize + 1;

        double[][] output = new double[outRows][outCols];
        for (int i = 0; i < input.length; i++) {
            for (int j = 0; j < input[0].length; j++) {
                output[i * stepSize][j * stepSize] = input[i][j];
            }
        }
        return output;
    }
\end{lstlisting}

Damit ist es aber noch nicht getan. Wenn die Convolution mit dem Hilfsarray abgeschlossen ist, erhalten wir ein Array welches die Änderungsraten enthält, die wir von den Werten im bisherigen Filter abziehen müssen.
Aber danach müssen wir noch die Werte berechnen, die wir an die nächste Schicht im Backpropagation Verfahren geben. Genau wie zuvor bei den Fully Connected Layern, leiten wir dann nicht mehr nach den Gewichten, oder hier eben den Filtern ab, sondern nach den Werten in den Input Bildern. Dadurch entsteht wieder eine Ableitung, nämlich $\frac {dC} {dX}$, wobei $X$ die Outputs der vorherigen Schicht repräsentiert, also die Input Bilder der aktuellen Schicht.

Zur Veranschaulichung für unser Beispiel, hier noch einmal die Vier Formeln zur Berechnung der Feature Map unseres Beispiels:
$$O_{11} = X_{11}F_{11}+X_{12}F_{12}+X_{13}F_{13}+X_{21}F_{21}+X_{22}F_{22}+X_{23}F_{23}+X_{31}F_{31}+X_{32}F_{32}+X_{33}F_{33}$$
$$O_{12} = X_{13}F_{11}+X_{14}F_{12}+X_{15}F_{13}+X_{23}F_{21}+X_{24}F_{22}+X_{25}F_{23}+X_{33}F_{31}+X_{34}F_{32}+X_{35}F_{33}$$
$$O_{21} = X_{31}F_{11}+X_{32}F_{12}+X_{33}F_{13}+X_{41}F_{21}+X_{42}F_{22}+X_{43}F_{23}+X_{51}F_{31}+X_{52}F_{32}+X_{53}F_{33}$$
$$O_{22} = X_{33}F_{11}+X_{34}F_{12}+X_{35}F_{13}+X_{43}F_{21}+X_{44}F_{22}+X_{45}F_{23}+X_{53}F_{31}+X_{54}F_{32}+X_{55}F_{33}$$

Ziel ist es, herauszufinden, welchen Einfluss die Outputs der vorherigen Schicht auf die Cost Funktion hatte.
Wir sehen uns ein paar Beispiele an. Wenn wir den Ersten Wert des Bildes betrachten, dann war nur der erste Wert im Filter jemals daran beteiligt, den output zu errechnen. So wird die Kettenregel angewendet:

$$\frac {dC} {dX_{11}} = 
\frac {dC}{dO_{11}} \frac {dO}{dX_{11}} =
\frac {dC}{dO_{11}} F_{11}$$
Um das ein wenig verständlicher darzustellen, visuallisieren wir das einmal Farblich:
%TODO Bild einfürgen für den Oben genannten Umstand

\begin{figure}[H]
\centering
\includegraphics[scale=0.80]{Images/TemporaryPlaceholders/Farbliche Visualisierung der Fehlerrückführung über die Inputs X11.png}
\caption{Farbliche Visualisierung der Fehlerrückführung über die Inputs X11}
\label{Farbliche Visualisierung der Fehlerrückführung über die Inputs X11}
\end{figure}

Nur beim ersten Schritt, wenn der Filter ganz oben in der Linken Ecke des Bildes ist, wird der Input $X_{11}$ verwendet. Auch bei $X_{12}$ gibt es nur ein Vorkommen in den Rechnungen:

$$\frac {dC} {dX_{12}} = \frac {dC}{dO_{11}} F_{12}$$

%TODO Ersetze das Bild Dringend
\begin{figure}[H]
\centering
\includegraphics[scale=0.80]{Images/TemporaryPlaceholders/Farbliche Visualisierung der Fehlerrückführung über die Inputs X12.png}
\caption{Farbliche Visualisierung der Fehlerrückführung über die Inputs X12}
\label{Farbliche Visualisierung der Fehlerrückführung über die Inputs X12}
\end{figure}

Anders sieht es allerdings z.B. bei $X_{31}$ aus. Dieser Wert wird sowohl durch den ersten Schritt verwendet, als auch durch den vierten. Das Spiegelt sich in der Ableitung wieder:
$$\frac {dC} {dX_{31}} = \frac {dC}{dO_{11}} F_{31} + \frac {dC}{dO_{21}} F_{11}$$

%TODO Ersetze das Bild Dringend
\begin{figure}[H]
\centering
\includegraphics[scale=0.80]{Images/TemporaryPlaceholders/Farbliche Visualisierung der Fehlerrückführung über die Inputs X31.png}
\caption{Farbliche Visualisierung der Fehlerrückführung über die Inputs X31}
\label{Farbliche Visualisierung der Fehlerrückführung über die Inputs X31}
\end{figure}

Hier wird es schon sichtbar, dass die Error Map Horizontal und Vertikal verdreht verwendet wird, aber das wird noch sichtbarer, wenn wir uns $X_{33}$ ansehen. Dieser Wert kommt in allen vier Schritten vor:

$$\frac {dC} {dX_{33}} = \frac {dC}{dO_{11}} F_{33} + \frac {dC}{dO_{31}} F_{11} + \frac {dC}{dO_{21}} F_{13} + \frac {dC}{dO_{22}} F_{11}$$

%TODO Ersetze das Bild Dringend
\begin{figure}[H]
\centering
\includegraphics[scale=0.80]{Images/TemporaryPlaceholders/Farbliche Visualisierung der Fehlerrückführung über die Inputs X31.png}
\caption{Farbliche Visualisierung der Fehlerrückführung über die Inputs X33}
\label{Farbliche Visualisierung der Fehlerrückführung über die Inputs X33}
\end{figure}

Wenn man diese Schritte so weiterführen würde, dann würden einem die Folgenden Dinge auffallen:
\begin{itemize}
  \item Die Error Map wird Vertikal und Horizontal gespiegelt verwendet
  \item Die Error Map wird so wie zuvor auch, entsprechend der Schrittgröße auseinander gezerrt  
  \item Bei der oben "Verwendung" genannten Operation handelt es sich um eine Full Cross Correlation
\end{itemize}

Diese Operation kann also auch relativ einfach umgesetzt werden. Wenn wir eine Full Cross-Correlation zwischen der Fehler Map und den bisherigen Filtern ausführen, dann entsteht tatsächlich ein Array, welches die Maße der Input Bilder hat. Dieses Array enthält die Fehlermengen für die nächste Schicht im Backpropagation Verfahren. 

Fangen wir doch mit der Full Cross-Correlation an. Die Methode "fullConvolve" erhält die Aktuellen Filter und die umgekehrte Error Map als Input. Im Großen und ganzen können wir die Convolve Methode kopieren, allerdings müssen einige Änderungen vorgenommen werden.

\begin{lstlisting}[language=Java]
private double[][] fullConvolve(double[][] currentFilter, double[][] flippedError) {
        int outRows = (currentFilter.length + flippedError.length) + 1;
        int outCols = (currentFilter[0].length + flippedError[0].length) + 1;
\end{lstlisting}
Zuerst müssen die Outputs anders berechnet werden. bei der Full Cross-Correlation entstehen mehr berechnete Werte. 
$$H_{out} = (H + filter\_height)-1$$
$$W_{out} = (W + filter\_ width)-1$$
Jedoch kommt es leider immer wieder vor, dass durch die Rundungen beim berechnen der Output Dimensionen nicht ganz die gleichen Matrizen entstehen, wie sie erwartet werden. Durch einige Tests konnte sichergestellt werden, dass eventuelle Überhänge keine Notwendigen Informationen enthalten. Allerdings muss man hier aufpassen, dass die "add" Methode, welche die Werte von zwei Arrays addiert, nur über das kleinere Array iteriert. Diese Stellen im Code funktionieren soweit, in Zukünftigen Anpassungen können sie aber verbessert werden. 

Als nächstes werden die Dimensionen des Filters gespeichert. Über diesen Filter wird wie über das input Bild iteriert, daher benötigen wir die Abmaße. Danach nehmen wir die Dimensionen der umgekehrten und auseinander gezehrten Error Map, diese werden nicht nur für die Iteration in den inneren Schleifen benötigt, sondern diesmal auch für die Begrenzung in den Äußeren Schleifen. 
\begin{lstlisting}[language=Java]
        int inRows = currentFilter.length;
        int inCols = currentFilter[0].length;

        int fRows = flippedError.length;
        int fCols = flippedError[0].length;

        double[][] output = new double[outRows][outCols];
        
\end{lstlisting}
        Da es sich hierbei um eine Full Cross-Correlation handelt, wird die erste Position, an welcher der Filter angelegt wird, außerhalb des Input Bildes sein. Das Reflektieren wir dadurch, dass die Startposition in der Schleife die negative Länge der Filters plus eins ist. Dadurch ist nur der äußerste Wert i, Filter über dem ersten Wert im Input Bild.
\begin{lstlisting}[language=Java]

        int outRow = 0;
        int outCol;

        for (int i = -fRows +1; i < inRows; i++) {
            outCol = 0;
            for (int j = -fCols +1; j < inCols; j++) {

                double sum = 0.0;

\end{lstlisting}
Vor den inneren Schleifen, welche über alle Felder des Filters iterieren, initiieren wir die "sum", welchem die einzelnen berechnungen über allen Einträgen des Filters aufaddiert werden. Die inneren Schleifen funktionieren genau wie zuvor auch, mit dem einzigen Unterschied, dass wir einen Test einbauen müssen, der überprüft, ob ein Wert, der unter einem Filter Eintrag liegt außerhalb der Input Matrix liegt. Dadurch vermeiden wir Index out of Bound Errors.
\begin{lstlisting}[language=Java]
                for (int x = 0; x < fRows; x++) {
                    for (int y = 0; y < fCols; y++) {
                        int inputRowIndex = i + x;
                        int inputColIndex = j + y;

                        if (inputRowIndex >= 0 && inputColIndex >= 0 && inputRowIndex < inRows
                                && inputColIndex < inCols) {
                            double value = flippedError[x][y] * currentFilter[inputRowIndex][inputColIndex];
                            sum += value;
                        }
                    }
                }
                
\end{lstlisting}
Zuletz werden die Ergebnisse in dem output Array gespeichert. Es kann vorkommen, dass dieses Größer ist, als die Abmaße der input Bilder, allerdings sollte das kein Problem sein. 
\begin{lstlisting}[language=Java]
                output[outRow][outCol] = sum;
                outCol++;
            }
            outRow++;
        }
        return output;
    }
\end{lstlisting}

Kommen wir nun zum Kern, dem eigentlichen "backPropagation" Algorithmus. Wie Oben besprochen, benötigen wir eine Liste "filtersDelta" mit den Filter, welche die Änderungsraten für die Aktuellen Filter enthalten, und eine Liste mit den Ableitungen der Cost Funktion im Bezug auf die aktuellen Filter, "dLd0PreviousLayer", welche wir an die vorherige Schicht weiterleiten werden.
Die "filtersDelta" Liste sollte so initialisiert werden, dass sie genau der Liste mit den Filtern entspricht, das heißt die gleiche Anzahl an Matrizen, und diese in gleicher Form und Größe wie die Filter.

\begin{lstlisting}[language=Java]
public void backPropagation(List<double[][]> dLdO) {
        List<double[][]> filtersDelta = new ArrayList<>();
        List<double[][]> dLd0PreviousLayer = new ArrayList<>();;
        for (int f = 0; f < filters.size(); f++) {
            filtersDelta.add(new double[filterSize][filterSize]);
        }
\end{lstlisting}
Nun iterieren wir über alle Input Bilder, die bei dem Forwardpass zwischengespeichert wurden. Wir initialisieren eine Matrix, "errorForInput", um die Fehler für die nächste Schicht aufadieren zu können.
\begin{lstlisting}[language=Java]
        for (int i = 0; i < lastInput.size(); i++) {
            double[][] errorForInput = new double[inRows][inCols];
\end{lstlisting}
Und dann iterieren wir für jeden Filter, den wir haben und berechnen die Werte, so wie oben beschrieben.
Zuerst speichern wir den Aktuellen Filter zwischen, damit wir ihn nachher unverändert verwenden können. Dann holen wir uns die aktuelle Error Map, und Speichern diese auch.
\begin{lstlisting}[language=Java]
            for (int f = 0; f < filters.size(); f++) {
                double[][] currentFilter = filters.get(f);
                double[][] error = dLdO.get(i * filters.size() + f);
\end{lstlisting}
Der Error muss entsprechend der Schrittgröße auseinandergezogen werden, und kann dann an die "convolve" Methode übergeben werden. Die Schrittgröße, die an die Methode übergeben wir, ist hier immer eins, da wir bereits durch das Strecken der Error Map dafür sorgen, dass die jeweilige Schrittgröße berücksichtigt wird.
\begin{lstlisting}[language=Java]
                double[][] spacedError = spaceArray(error);
                double[][] dLdF = convolve(lastInput.get(i), spacedError, 1);
\end{lstlisting}
nachdem wir also die Änderungsraten berechnet haben, müssen wir sie auch abziehen. Dafür verwenden wir die Methode multiply, welche jeden Wertt eines Arrays mit einem übergebenem Skalar Multipliziert. Dadurch kehren wir die Werte um, wonach sie danach mithilfe der "add" Methode zu den bisherigen Filter Änderungsraten hinzugefügt werden.
\begin{lstlisting}[language=Java]
                double[][] delta = multiply(dLdF, learnRate * -1);
                double[][] newTotalDelta = add(filtersDelta.get(f), delta);
                filtersDelta.set(f, newTotalDelta);
\end{lstlisting}
Zuletzt kehren wir die gezerrte Error Map auf beiden Achsen um, führen dann die Full Cross-Correlation zwischen ihr und dem aktuellen Filter aus, addieren das Ergebnis auf die bisherige "errorForInput" Matrix, die nachher weitergereicht wird. Und damit ist das Ende der inneren Schleife erreicht.
\begin{lstlisting}[language=Java]
                double[][] flippedError = flipArray(spacedError);
                errorForInput = add(errorForInput, fullConvolve(currentFilter, flippedError));
            }
\end{lstlisting}
Die Matrix "errorForInput" wird in die Liste der Werte für die nächste Schicht eingefügt. Das war der letzte Schritt der Schleife. Zum Schluss müssen die Filter nuch noch mit den Änderungsraten in "filtersDelta" verrechnet werden, und falls es eine vorherige Schicht gibt, sollen auch die Error Maps an die nächste Backpropagation methode weitergereicht werden.
\begin{lstlisting}[language=Java]
            dLd0PreviousLayer.add(errorForInput);
        }
        for (int f = 0; f < filters.size(); f++) {
            double[][] modified = add(filtersDelta.get(f), filters.get(f));
            filters.set(f, modified);
        }
        if(previousLayer != null){
            previousLayer.backPropagation(dLd0PreviousLayer);
        }
    }
\end{lstlisting}

Damit kommen wir zum Schluss dieses Kapitels. Der gesamte Code ist auf GitHub zu finden:
https://github.com/AkumaKater/Bachelorarbeit
https://git.inf.fh-dortmund.de/01/jafor003/Bachelorarbeit
Die nächsten Kapitel behandeln den Code, der die Schichten verwaltet. 























\cleardoublepage
\section{Unterstützungs Templates}
Die Gliederung dieser Arbeit, entspricht einer organischen Herangehensweise oder einer Anleitung, wie ein Netzwerk aufgebaut wird. Jedes Kapitel entspricht einem Teil des Netzwerkes, also den Funktionen, der Initialisierung, der Query oder Abfrage und dem Lern- oder Backpropagation-Algorithmus. Jedes der Kapitel startet mit einer Übersicht, über die Funktionalität, erläutert die Theorie dahinter, teilweise auch mathematisch, und schließt, mit dem daraus resultierenden Code ab. 


\begin{figure}[H]
\centering
\includegraphics[scale=0.27]{./Images/BA_003_tensorflow-keras-cnn-hierarchical-structure.png}
\caption{Tiefe der Abstraktion von Merkmalen [3] test}
\label{Tiefe der Abstraktion von Merkmalen [3] test}
\end{figure}


\begin{itemize}
  \item Dendriten
  \item der Zellkörper
  \item das Axon
\end{itemize}

\begin{lstlisting}[language=Java]
public class NeuralNetwork {
    Layer[] layers;
    }
}
\end{lstlisting}

$h$ kürzen:
$$\frac{\Delta e}{\Delta w}=w+w+h$$
$$\frac{\Delta e}{\Delta w}=2w+h$$Und jetzt zum Interessanten Teil. Da wir $h$ nicht gleich 0 setzten können, können wir allerdings $h$ gegen 0 laufen lassen, dann verwenden wir die Leibniz-Notation. Das bedeutet, dass wir anstatt  $\Delta w$ und  $\Delta e$, wobei $\Delta$ eine sehr kleine Vergrößerung darstellt, jetzt $dw$ und $de$ verwenden, wobei $d$ für eine unendlich kleine Vergrößerung steht, eine sogenannte Infinitesimalzahl.
Das sieht dann ungefähr so aus:
$$\frac{de}{dw}=\lim_{h\to 0} 2w +h$$
$$\frac{de}{dw}=2w$$


\section{Einleitung}
\subsection{Motivation}
Neuronale Netzwerke werden vor allem für Klassifikationsverfahren verwendet. In der Praxis gibt es viele Anwendungsbereiche, in denen es vorteilhaft ist, große Mengen von Daten automatisch zu klassifizieren. Einige Beispiele, wären die Bild- und Schrifterkennung, die man dazu verwendet, Kennschilder von Autos, maschinell auszulesen. Solche Technologien werden immer häufiger auf Parkplätzen und Autobahnen eingesetzt. Aber, auch fast jedes Handy kann mittlerweile Schrift erkennen, die mit der Kamera aufgenommen wird. Auch in der Medizin, beim Auswerten von Röntgenbildern, in der Biologie, zum Erkennen von Pflanzen auf Fotos und noch vielem mehr, werden Neuronale Netzwerke inzwischen eingesetzt.\\

\cleardoublepage
% \phantomsection
\sloppy
\section{Quellen}
\begin{itemize}
\item 1. B. Lenze, Einführung in die Mathematik neuronaler Netze. Berlin: Logos Verlag; 2009.
\item 2. Alexey Kravets (02.03.2024), "Forward and Backward propagation of Max Pooling Layer in Convolutional Neural Networks", URL: https://towardsdatascience.com/forward-and-backward-propagation-of-pooling-layers-in-convolutional-neural-networks-11e36d169bec
\item 3. Bill Kromydas (08.03.2024), "Understanding Convolutional Neural Network (CNN): A Complete Guide", URL: https://learnopencv.com/understanding-convolutional-neural-networks-cnn/



\item 4. "Ableitung der Sigmoid-Funktion" URL: \url{https://ichi.pro/de/ableitung-der-sigmoid-funktion-91708302791054}
\item 5. "What is the role of the bias in neural networks?" URL: \url{https://stackoverflow.com/questions/2480650/what-is-the-role-of-the-bias-in-neural-networks}.
\item 6. "How do I choose the optimal batch size?", URL: \url{https://ai.stackexchange.com/questions/8560/how-do-i-choose-the-optimal-batch-size}
\end{itemize}

\cleardoublepage
\section{Liste der Abbildungen}
\listoffigures
\end{document}